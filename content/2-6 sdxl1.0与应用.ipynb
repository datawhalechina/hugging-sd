{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-6 sdxl1.0与应用\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 章节目标\n",
    "- sdxl的概念\n",
    "- sdxl与传统sd模型的区别\n",
    "- sdxl使用的几种方式\n",
    "- 注意事项"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 概念和应用场景\n",
    "sdxl是一种用于文本到图像合成的潜在扩散模型，包含2个模型(base和refiner)和2步过程(①先使用基础模型base生成噪声潜在因素，再通过降噪细化模型refiner提升图片质量),其中基础模型base可以作为独立模块使用。同时可以使用两阶段通道(②先用基础模型base生成所需输出大小的图像，再使用img2img得到高质量图像)。其原理如下图所示，两种使用方式依赖于GPU显存(如果显存足够可以进行①，反之建议②)。\n",
    "论文地址：https://arxiv.org/abs/2307.01952\n",
    "\n",
    "<img alt=\"介绍\" height=\"360\" src=\"images/2-6 pipeline.png\" width=\"720\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 sdxl与传统sd模型的区别\n",
    "sdxl1.0具有以下新特性：\n",
    "- 更好的成像质量，拥有更生动，准确的颜色，在对比度，光照和阴影等方面表现更好。\n",
    "- 更智能的语言提示，相对比以前的模型，sdxl能用更少的提示词获得复杂，详细，美观的图像，同时对概念差异的理解更深。比如某些提示词有多种概念，sdxl更能理解这种差异。\n",
    "- 更高的分辨率，sdxl基础分辨率为1024x1024，sd1.5为512x512，sd2为768x768。\n",
    "- 更高级的控制，sdxl的微调模型，微调模型适应自定义数据能力更高，即使用更少的数据整理来生成自定义LoRAs或检查点。\n",
    "- 相比于传统sd，sdxl拥有三倍大的UNet主干，主要改进为：\n",
    "1. UNet中transformer块放到较低层去计算。\n",
    "2. 文本编码器从单个CLIP换成了OpenClip ViT-bigG和Clip Vit-L两个合并。拥有更智能的语言提示，也使得sd1.5和sd2所训练的中文对齐模型失效。\n",
    "3. 用cross-attention做文本条件注入，同时增加了来自OpenClip池化了的文本嵌入。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 sdxl使用的几种方式\n",
    "### 3.1 在线使用\n",
    "- 在Clipdrop上体验SDXL1.0:Clipdrop(https://clipdrop.co/stable-diffusion)\n",
    "- 在Stability AI平台上通过API使用sdxl1.0:Stability AI Platform(https://platform.stability.ai/)\n",
    "- 加入Stable Foundation Discord进行sdxl模型的实时测试: Stable Foundation Discord(https://discord.com/)\n",
    "- DreamStudio也提供sdxl1.0用于图像生成: DreamStudio(https://dreamstudio.ai/)\n",
    "### 3.2 本地部署\n",
    "#### 3.2.1 WebUI\n",
    "(程序需要一定显存才能平稳运行，若出现内存不足错误。 可以通过命令行参数启用各种优化[或开启低显存模式，整合包有该选项]，牺牲一些/很多速度来支持使用更少的VRAM)\n",
    "- 方法一：利用别人的整合包一键安装(B站搜索秋葉aaaki，已整合webui)，只需下载sdxl的base和refiner权重以及sdxl VAE文件(参考博客：https://zhuanlan.zhihu.com/p/646885743)webui页面如下所示。\n",
    "<img alt=\"介绍\" height=\"360\" src=\"images/2-6-1 webuipage.png\" width=\"720\"/>\n",
    "- 方法二：利用github项目配置webui，需要python>=3.10(GitHub作者使用3.10.6)，cuda，git，项目地址：https://github.com/AUTOMATIC1111/stable-diffusion-webui\n",
    "1. 安装：git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git [若出现网络问题，下载安装包安装]\n",
    "2. 利用命令管理器或者vscode运行stable-diffusion-webui下的web-user(命令为start web-use)r，若出现网络问题，可以参考博客：https://blog.csdn.net/leah126/article/details/132041583 或者手动下载所需模型到stable-diffusion-webui/repositories和sdxl1.0权重到stable-diffusion-webui/modules/models，所需下载的模型和权重的GitHub路径会在cmd的报错页面显示。\n",
    "3. 汉化：在extensions标签里可以下载汉化包，下载完成后切换至已安装界面勾选启用刚下载的汉化包插件，然后点击应用并重启界面。(或下载别的地方汉化包然后直接把汉化包放在stable-diffusion-webui/extensions目录下)\n",
    "<img alt=\"介绍\" height=\"360\" src=\"images/2-6-2 chinese.png\" width=\"720\"/>\n",
    "#### 3.2.2 利用hugging face接口\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
