{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1 概念\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2022年，stable diffusion发布，开启了AIGC的时代，各种视觉生成模型/应用层出不穷，比较典型的应用还有Midjourney，以及DALL-E2，现在openai已经逐步开始测试DALL-E3。基于diffusion的图像生成，视频生成逐步成为目前的一个研究和应用趋势。  \n",
    "以Chatgpt为典型的这类模型是文本生成模型，那么视觉生成模型就不难理解，顾名思义，针对视觉任务（图像、视频），进行内容生成，根据输入的文字、图像生成图像、视频等。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://github.com/CompVis/stable-diffusion/raw/main/assets/stable-samples/txt2img/merged-0006.png)\n",
    "<center>stable diffusion</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[]()  midjourney"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 什么是视觉生成大模型？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "视觉生成是计算机视觉领域的一个重要研究方向，指根据特定的输入（随机噪声、文本、图像和视频等）生成与目标分布相匹配的图像或视频，可以实现对图像和视频的生成、美化、渲染和重建等操作。  \n",
    "视觉生成技术在日常生活中有广泛的应用，比如视觉设计、图像/视频制作等。  \n",
    "视觉生成已经成为机器学习领域热门的方向之一。  \n",
    "视觉生成的目标是生成尽可能真实的数据，其关键在于构造生成模型。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[深度对抗视觉生成综述](http://www.cjig.cn/jig/ch/reader/create_pdf.aspx?file_no=20211201&flag=1&year_id=2021&quarter_id=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 视觉生成模型与自然语言生成模型的区别？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[自然语言生成综述](http://www.joca.cn/CN/10.11772/j.issn.1001-9081.2020071069)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自然语言最终要生成的是文本信息。  \n",
    "典型任务有：文本到文本生成、数据到文本生成和图像到文本生成。  \n",
    "应用场景  \n",
    "NLG 技术具有极为广泛的应用价值，应 用于智能问答对话系统和机器翻译系统时，可实现更为智能 便捷的人机交互；应用于机器新闻写作［2］ 、医学诊断报告生 成［3］ 和天气预报生成［4］ 等领域时，可实现文章报告自动撰写， 有效减轻人工工作；应用于文章摘要、文本复述领域时，可为 读者创造快速阅读条件等。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2 方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.1 生成对抗网络（GAN）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN网络，generative adversal network，全称是生成对抗网络。自2014年Ian Goodfellow提出了GAN以来，对GAN的各种研究如火如荼，GAN的各种变体也层出不穷。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://pic1.zhimg.com/80/v2-8fb3a568c252eeae621bd250ccb8b2cc_1440w.webp)\n",
    "<center>GAN相关论文发表情况</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN网络的核心在于“对抗”。GAN的设计思想就是一种对抗博弈的思想。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先举一个小例子说明一下这种对抗博弈的思想：两个人，一个人用剑进攻，一个人用盾防守，在对抗的过程中，进攻的一方不断地调整战术，试图攻破对方的防守；而另一个人，在对抗的过程中，不断地调整，或者把盾变得更加厚实，试图抵挡对方的攻击。  \n",
    "在这个对抗的过程中，攻击者的技术会越来越高超。  \n",
    "这就是对抗博弈的一个思想。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN网络的基本构成就是一个生成器和一个判别器，分别对应上述例子中的进攻者和防御者。  \n",
    "以手写数字的数据集为例，定义一个模型作为生成器，一个模型（一般是分类器）作为判别器。生成器用来将输入的噪声信号转化为手写数字数据集中的图像；同时判别器判断图片是来自手写数据集还是生成器生成的（即图像的“真伪”）。  \n",
    "在这种“对抗博弈”的过程中，生成器不断生成接近数据集中数据的图像，最终达到以假乱真的效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![GAN的基本结构](https://pic4.zhimg.com/80/v2-5ca6a701d92341b8357830cc176fb8a3_1440w.webp)\n",
    "<center>GAN的基本结构</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下是GAN网络的基本训练流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导包\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据准备\n",
    "# 对数据做归一化 （-1， 1）\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),         # 将数据转换成Tensor格式，channel, high, witch,数据在（0， 1）范围内\n",
    "    transforms.Normalize(0.5, 0.5) # 通过均值和方差将数据归一化到（-1， 1）之间\n",
    "])\n",
    "\n",
    "# 下载数据集\n",
    "train_ds = torchvision.datasets.MNIST('data',\n",
    "                                      train=True,\n",
    "                                      transform=transform,\n",
    "                                      download=True)\n",
    "                                      \n",
    "# 设置dataloader\n",
    "dataloader = torch.utils.data.DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "\n",
    "# 返回一个批次的数据\n",
    "imgs, _ = next(iter(dataloader))\n",
    "\n",
    "# imgs的大小\n",
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义生成器\n",
    "# 输入是长度为 100 的 噪声（正态分布随机数）\n",
    "# 输出为（1， 28， 28）的图片\n",
    "# linear 1 :   100----256\n",
    "# linear 2:    256----512\n",
    "# linear 2:    512----28*28\n",
    "# reshape:     28*28----(1, 28, 28)\n",
    "\n",
    "class Generator(nn.Module): #创建的 Generator 类继承自 nn.Module\n",
    "    def __init__(self): # 定义初始化方法\n",
    "        super(Generator, self).__init__() #继承父类的属性\n",
    "        self.main = nn.Sequential( #使用Sequential快速创建模型\n",
    "                                  nn.Linear(100, 256),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Linear(256, 512),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Linear(512, 28*28),\n",
    "                                  nn.Tanh()                     # 输出层使用Tanh()激活函数，使输出-1, 1之间\n",
    "        )\n",
    "    def forward(self, x):              # 定义前向传播 x 表示长度为100 的noise输入\n",
    "        img = self.main(x)\n",
    "        img = img.view(-1, 28, 28) #将img展平，转化成图片的形式，channel为1可写可不写\n",
    "        return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义判别器\n",
    "## 输入为（1， 28， 28）的图片  输出为二分类的概率值，输出使用sigmoid激活 0-1\n",
    "# BCEloss计算交叉熵损失\n",
    "\n",
    "# nn.LeakyReLU   f(x) : x>0 输出 x， 如果x<0 ,输出 a*x  a表示一个很小的斜率，比如0.1\n",
    "# 判别器中一般推荐使用 LeakyReLU\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "                                  nn.Linear(28*28, 512), #输入是28*28的张量，也就是图片\n",
    "                                  nn.LeakyReLU(), # 小于0的时候保存一部分梯度\n",
    "                                  nn.Linear(512, 256),\n",
    "                                  nn.LeakyReLU(),\n",
    "                                  nn.Linear(256, 1), # 二分类问题，输出到1上\n",
    "                                  nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = self.main(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化模型、优化器及损失计算函数\n",
    "# 定义设备\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# 初始化模型\n",
    "gen = Generator().to(device)\n",
    "dis = Discriminator().to(device)\n",
    "# 优化器\n",
    "d_optim = torch.optim.Adam(dis.parameters(), lr=0.0001)\n",
    "g_optim = torch.optim.Adam(gen.parameters(), lr=0.0001)\n",
    "# 损失函数\n",
    "loss_fn = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘图函数\n",
    "def gen_img_plot(model, epoch, test_input):\n",
    "    prediction = np.squeeze(model(test_input).detach().cpu().numpy())\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    for i in range(16):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow((prediction[i] + 1)/2) # 确保prediction[i] + 1)/2输出的结果是在0-1之间\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "test_input = torch.randn(16, 100, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN的训练\n",
    "# 保存每个epoch所产生的loss值\n",
    "D_loss = []\n",
    "G_loss = []\n",
    "\n",
    "# 训练循环\n",
    "for epoch in range(20): #训练20个epoch\n",
    "   d_epoch_loss = 0 # 初始损失值为0\n",
    "   g_epoch_loss = 0\n",
    "   # len(dataloader)返回批次数，len(dataset)返回样本数\n",
    "   count = len(dataloader)\n",
    "   # 对dataloader进行迭代\n",
    "   for step, (img, _) in enumerate(dataloader): # enumerate加序号\n",
    "       img = img.to(device) #将数据上传到设备\n",
    "       size = img.size(0) # 获取每一个批次的大小\n",
    "       random_noise = torch.randn(size, 100, device=device)  # 随机噪声的大小是size个\n",
    "       \n",
    "       d_optim.zero_grad() # 将判别器前面的梯度归0\n",
    "       \n",
    "       real_output = dis(img)      # 判别器输入真实的图片，real_output是对真实图片的预测结果 \n",
    "       \n",
    "       # 得到判别器在真实图像上的损失\n",
    "       # 判别器对于真实的图片希望输出的全1的数组，将真实的输出与全1的数组进行比较\n",
    "       d_real_loss = loss_fn(real_output, \n",
    "                             torch.ones_like(real_output))      \n",
    "       d_real_loss.backward() # 求解梯度\n",
    "       \n",
    "       \n",
    "       gen_img = gen(random_noise)    \n",
    "       # 判别器输入生成的图片，fake_output是对生成图片的预测\n",
    "       # 优化的目标是判别器，对于生成器的参数是不需要做优化的，需要进行梯度阶段，detach()会截断梯度，\n",
    "       # 得到一个没有梯度的Tensor，这一点很关键\n",
    "       fake_output = dis(gen_img.detach()) \n",
    "       # 得到判别器在生成图像上的损失\n",
    "       d_fake_loss = loss_fn(fake_output, \n",
    "                             torch.zeros_like(fake_output))      \n",
    "       d_fake_loss.backward() # 求解梯度\n",
    "       \n",
    "       d_loss = d_real_loss + d_fake_loss # 判别器总的损失等于两个损失之和\n",
    "       d_optim.step() # 进行优化\n",
    "       \n",
    "       g_optim.zero_grad() # 将生成器的所有梯度归0\n",
    "       fake_output = dis(gen_img) # 将生成器的图片放到判别器中，此时不做截断，因为要优化生成器\n",
    "       # 生层器希望生成的图片被判定为真\n",
    "       g_loss = loss_fn(fake_output, \n",
    "                        torch.ones_like(fake_output))      # 生成器的损失\n",
    "       g_loss.backward() # 计算梯度\n",
    "       g_optim.step() # 优化\n",
    "       \n",
    "       # 将损失累加到定义的数组中，这个过程不需要计算梯度\n",
    "       with torch.no_grad():\n",
    "           d_epoch_loss += d_loss\n",
    "           g_epoch_loss += g_loss\n",
    "     \n",
    "   # 计算每个epoch的平均loss，仍然使用这个上下文关联器\n",
    "   with torch.no_grad():\n",
    "       # 计算平均的loss值\n",
    "       d_epoch_loss /= count\n",
    "       g_epoch_loss /= count\n",
    "       # 将平均loss放入到loss数组中\n",
    "       D_loss.append(d_epoch_loss.item())\n",
    "       G_loss.append(g_epoch_loss.item())\n",
    "       # 打印当前的epoch\n",
    "       print('Epoch:', epoch)\n",
    "       # 调用绘图函数\n",
    "       gen_img_plot(gen, epoch, test_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 整体代码\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "# 对数据做归一化 （-1， 1）\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),         # 将数据转换成Tensor格式，channel, high, witch,数据在（0， 1）范围内\n",
    "    transforms.Normalize(0.5, 0.5) # 通过均值和方差将数据归一化到（-1， 1）之间\n",
    "])\n",
    "\n",
    "# 下载数据集\n",
    "train_ds = torchvision.datasets.MNIST('data',\n",
    "                                      train=True,\n",
    "                                      transform=transform,\n",
    "                                      download=True)\n",
    "                                      \n",
    "# 设置dataloader\n",
    "dataloader = torch.utils.data.DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "\n",
    "# 返回一个批次的数据\n",
    "imgs, _ = next(iter(dataloader))\n",
    "\n",
    "# imgs的大小\n",
    "imgs.shape\n",
    "\n",
    "# 输入是长度为 100 的 噪声（正态分布随机数）\n",
    "# 输出为（1， 28， 28）的图片\n",
    "# linear 1 :   100----256\n",
    "# linear 2:    256----512\n",
    "# linear 2:    512----28*28\n",
    "# reshape:     28*28----(1, 28, 28)\n",
    "\n",
    "class Generator(nn.Module): #创建的 Generator 类继承自 nn.Module\n",
    "    def __init__(self): # 定义初始化方法\n",
    "        super(Generator, self).__init__() #继承父类的属性\n",
    "        self.main = nn.Sequential( #使用Sequential快速创建模型\n",
    "                                  nn.Linear(100, 256),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Linear(256, 512),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Linear(512, 28*28),\n",
    "                                  nn.Tanh()                     # 输出层使用Tanh()激活函数，使输出-1, 1之间\n",
    "        )\n",
    "    def forward(self, x):              # 定义前向传播 x 表示长度为100 的noise输入\n",
    "        img = self.main(x)\n",
    "        img = img.view(-1, 28, 28) #将img展平，转化成图片的形式，channel为1可写可不写\n",
    "        return img\n",
    "\n",
    "## 输入为（1， 28， 28）的图片  输出为二分类的概率值，输出使用sigmoid激活 0-1\n",
    "# BCEloss计算交叉熵损失\n",
    "\n",
    "# nn.LeakyReLU   f(x) : x>0 输出 x， 如果x<0 ,输出 a*x  a表示一个很小的斜率，比如0.1\n",
    "# 判别器中一般推荐使用 LeakyReLU\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "                                  nn.Linear(28*28, 512), #输入是28*28的张量，也就是图片\n",
    "                                  nn.LeakyReLU(), # 小于0的时候保存一部分梯度\n",
    "                                  nn.Linear(512, 256),\n",
    "                                  nn.LeakyReLU(),\n",
    "                                  nn.Linear(256, 1), # 二分类问题，输出到1上\n",
    "                                  nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = self.main(x)\n",
    "        return x\n",
    "\n",
    "# 定义设备\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# 初始化模型\n",
    "gen = Generator().to(device)\n",
    "dis = Discriminator().to(device)\n",
    "# 优化器\n",
    "d_optim = torch.optim.Adam(dis.parameters(), lr=0.0001)\n",
    "g_optim = torch.optim.Adam(gen.parameters(), lr=0.0001)\n",
    "# 损失函数\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "\n",
    "def gen_img_plot(model, epoch, test_input):\n",
    "    prediction = np.squeeze(model(test_input).detach().cpu().numpy())\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    for i in range(16):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow((prediction[i] + 1)/2) # 确保prediction[i] + 1)/2输出的结果是在0-1之间\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "test_input = torch.randn(16, 100, device=device)\n",
    "\n",
    " # 保存每个epoch所产生的loss值\n",
    "D_loss = []\n",
    "G_loss = []\n",
    "\n",
    "# 训练循环\n",
    "for epoch in range(20): #训练20个epoch\n",
    "    d_epoch_loss = 0 # 初始损失值为0\n",
    "    g_epoch_loss = 0\n",
    "    # len(dataloader)返回批次数，len(dataset)返回样本数\n",
    "    count = len(dataloader)\n",
    "    # 对dataloader进行迭代\n",
    "    for step, (img, _) in enumerate(dataloader): # enumerate加序号\n",
    "        img = img.to(device) #将数据上传到设备\n",
    "        size = img.size(0) # 获取每一个批次的大小\n",
    "        random_noise = torch.randn(size, 100, device=device)  # 随机噪声的大小是size个\n",
    "        \n",
    "        d_optim.zero_grad() # 将判别器前面的梯度归0\n",
    "        \n",
    "        real_output = dis(img)      # 判别器输入真实的图片，real_output是对真实图片的预测结果 \n",
    "        \n",
    "        # 得到判别器在真实图像上的损失\n",
    "        # 判别器对于真实的图片希望输出的全1的数组，将真实的输出与全1的数组进行比较\n",
    "        d_real_loss = loss_fn(real_output, \n",
    "                              torch.ones_like(real_output))      \n",
    "        d_real_loss.backward() # 求解梯度\n",
    "        \n",
    "        \n",
    "        gen_img = gen(random_noise)    \n",
    "        # 判别器输入生成的图片，fake_output是对生成图片的预测\n",
    "        # 优化的目标是判别器，对于生成器的参数是不需要做优化的，需要进行梯度阶段，detach()会截断梯度，\n",
    "        # 得到一个没有梯度的Tensor，这一点很关键\n",
    "        fake_output = dis(gen_img.detach()) \n",
    "        # 得到判别器在生成图像上的损失\n",
    "        d_fake_loss = loss_fn(fake_output, \n",
    "                              torch.zeros_like(fake_output))      \n",
    "        d_fake_loss.backward() # 求解梯度\n",
    "        \n",
    "        d_loss = d_real_loss + d_fake_loss # 判别器总的损失等于两个损失之和\n",
    "        d_optim.step() # 进行优化\n",
    "        \n",
    "        g_optim.zero_grad() # 将生成器的所有梯度归0\n",
    "        fake_output = dis(gen_img) # 将生成器的图片放到判别器中，此时不做截断，因为要优化生成器\n",
    "        # 生层器希望生成的图片被判定为真\n",
    "        g_loss = loss_fn(fake_output, \n",
    "                         torch.ones_like(fake_output))      # 生成器的损失\n",
    "        g_loss.backward() # 计算梯度\n",
    "        g_optim.step() # 优化\n",
    "        \n",
    "        # 将损失累加到定义的数组中，这个过程不需要计算梯度\n",
    "        with torch.no_grad():\n",
    "            d_epoch_loss += d_loss\n",
    "            g_epoch_loss += g_loss\n",
    "      \n",
    "    # 计算每个epoch的平均loss，仍然使用这个上下文关联器\n",
    "    with torch.no_grad():\n",
    "        # 计算平均的loss值\n",
    "        d_epoch_loss /= count\n",
    "        g_epoch_loss /= count\n",
    "        # 将平均loss放入到loss数组中\n",
    "        D_loss.append(d_epoch_loss.item())\n",
    "        G_loss.append(g_epoch_loss.item())\n",
    "        # 打印当前的epoch\n",
    "        print('Epoch:', epoch)\n",
    "        # 调用绘图函数\n",
    "        gen_img_plot(gen, epoch, test_input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.2 变分自编码器（VAE）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/vae2.png)\n",
    "<center>自编码器基本结构</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://pic1.zhimg.com/70/v2-e29d8d59a84a17b9199c8dbd5ade3eee_1440w.avis?source=172ae18b&biz_tag=Post)\n",
    "<center>变分自编码器基本结构</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE代码实现\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.datasets import MNIST\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "if not os.path.exists('./vae_img'):\n",
    "    os.mkdir('./vae_img')\n",
    "\n",
    "\n",
    "def to_img(x):\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), 1, 28, 28)\n",
    "    return x\n",
    "\n",
    "\n",
    "num_epochs = 100\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "    # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "dataset = MNIST('./data', transform=img_transform, download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 400)\n",
    "        self.fc21 = nn.Linear(400, 20)\n",
    "        self.fc22 = nn.Linear(400, 20)\n",
    "        self.fc3 = nn.Linear(20, 400)\n",
    "        self.fc4 = nn.Linear(400, 784)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        if torch.cuda.is_available():\n",
    "            eps = torch.cuda.FloatTensor(std.size()).normal_()\n",
    "        else:\n",
    "            eps = torch.FloatTensor(std.size()).normal_()\n",
    "        eps = Variable(eps)\n",
    "        return eps.mul(std).add_(mu)\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        # return F.sigmoid(self.fc4(h3))\n",
    "        return torch.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "\n",
    "strattime = datetime.datetime.now()\n",
    "model = VAE()\n",
    "if torch.cuda.is_available():\n",
    "    # model.cuda()\n",
    "    print('cuda is OK!')\n",
    "    model = model.to('cuda')\n",
    "else:\n",
    "    print('cuda is NO!')\n",
    "\n",
    "reconstruction_function = nn.MSELoss(size_average=False)\n",
    "# reconstruction_function = nn.MSELoss(reduction=sum)\n",
    "\n",
    "\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    \"\"\"\n",
    "    recon_x: generating images\n",
    "    x: origin images\n",
    "    mu: latent mean\n",
    "    logvar: latent log variance\n",
    "    \"\"\"\n",
    "    BCE = reconstruction_function(recon_x, x)  # mse loss\n",
    "    # loss = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
    "    KLD = torch.sum(KLD_element).mul_(-0.5)\n",
    "    # KL divergence\n",
    "    return BCE + KLD\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, data in enumerate(dataloader):\n",
    "        img, _ = data\n",
    "        img = img.view(img.size(0), -1)\n",
    "        img = Variable(img)\n",
    "        img = (img.cuda() if torch.cuda.is_available() else img)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(img)\n",
    "        loss = loss_function(recon_batch, img, mu, logvar)\n",
    "        loss.backward()\n",
    "        # train_loss += loss.data[0]\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            endtime = datetime.datetime.now()\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f} time:{:.2f}s'.format(\n",
    "                epoch,\n",
    "                batch_idx * len(img),\n",
    "                len(dataloader.dataset), \n",
    "                100. * batch_idx / len(dataloader),\n",
    "                loss.item() / len(img), \n",
    "                (endtime-strattime).seconds))\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "        epoch, train_loss / len(dataloader.dataset)))\n",
    "    if epoch % 10 == 0:\n",
    "        save = to_img(recon_batch.cpu().data)\n",
    "        save_image(save, './vae_img/image_{}.png'.format(epoch))\n",
    "\n",
    "torch.save(model.state_dict(), './vae.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.3 流模型（flow-based model）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://img-blog.csdnimg.cn/img_convert/4ad3616fbfd228d7619b6ec7a9967438.png)\n",
    "<center>三种基本生成模型结构的对比</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.4 扩散模型（Diffusion model）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dyh",
   "language": "python",
   "name": "dyh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
