{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 3-2 NeRFç¥ç»è¾å°„åœº\n",
    "  * [0 ç« èŠ‚ç›®æ ‡](#0-----)\n",
    "  * [1 å¤–è§‚å’Œå½¢çŠ¶è¡¨å¾](#1--------)\n",
    "    + [1.1 å½¢çŠ¶è¡¨å¾](#11-----)\n",
    "    + [1.2 å¤–è§‚è¡¨å¾](#12-----)\n",
    "  * [2 ç¥ç»è¾å°„åœºNeRF](#2------nerf)\n",
    "  * [3 ä»£ç æ¼”ç¤º](#3-----)\n",
    "    + [3.1 ä¾èµ–åº“å®‰è£…](#31------)\n",
    "    + [3.2 ä¸‹è½½å¹¶å‡†å¤‡æ•°æ®é›†](#32---------)\n",
    "    + [3.3 å»ºç«‹å¹¶å¯åŠ¨viewer](#33------viewer)\n",
    "    + [3.4 å¼€å§‹è®­ç»ƒ](#34-----)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0 ç« èŠ‚ç›®æ ‡\n",
    "- äº†è§£å¤–è§‚å’Œå½¢çŠ¶è¡¨å¾ï¼Œäº†è§£æ–°è§†è§’åˆæˆä»»åŠ¡\n",
    "- ç†è§£ç¥ç»æ¸²æŸ“åŸç†ï¼ˆNeRFï¼‰"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1 å¤–è§‚å’Œå½¢çŠ¶è¡¨å¾\n",
    "ä¸–ç•Œå¦‚æ­¤çº·ç¹å¤æ‚ï¼Ÿè¯¥ä»¥ä½•ç§å½¢å¼è¡¨ç¤ºå®ƒä»¬å‘¢ï¼Ÿæˆ‘ä»¬å¯ä»¥å°†æˆ‘ä»¬çœ‹åˆ°çš„ä¸–ç•Œè§£è€¦ä¸ºä¸¤ç§å½¢å¼ï¼Œé‡‡ç”¨çš„æ˜¯å¤–è§‚ï¼ˆappearanceï¼‰å’Œå½¢çŠ¶ï¼ˆshape/geometryï¼‰æ¥è¡¨ç¤ºä¸€ä¸ªç‰©ä½“æˆ–è€…åœºæ™¯ã€‚å…¶ä¸­å¤–è§‚åˆç»†åˆ†ä¸ºå…‰ç…§ã€æè´¨ç­‰ç­‰ã€‚é€šè¿‡å°†ç»„æˆä¸–ç•Œçš„å…‰ç…§ã€å‡ ä½•ã€æè´¨ç­‰å…ƒç´ è¿›è¡Œè§£è€¦ä»è€Œå¯ä»¥å¯¹åœºæ™¯è¿›è¡Œå‚æ•°åŒ–è¡¨ç¤ºã€‚è®¡ç®—æœºè§†è§‰ä¸­åˆ™æ˜¯ä»¥ç®€å•ç²—æš´çš„rgbè‰²å½©å€¼æ¥ç†è§£ä¸–ç•Œã€‚\n",
    "\n",
    "ä»–ä»¬ä¹‹é—´é€šè¿‡æ¸²æŸ“å’Œåæ¸²æŸ“çš„æ–¹å¼è¿›è¡Œè½¬æ¢ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œ[æ¥æº](https://www.bilibili.com/video/BV1d34y1n7fn/?spm_id_from=333.788&vd_source=f1a43cfabe61c271b4df05136a41d18c)\n",
    "\n",
    "<img alt=\"ä»‹ç»\" height=\"360\" src=\"images/3-2_1-rendering-and-inverse-rendering.png\" width=\"800\"/>\n",
    "\n",
    "\n",
    "å…¶ä¸­æ¸²æŸ“ä¾èµ–äºå½¢çŠ¶å’Œå¤–è§‚çš„è¡¨å¾ï¼Œå¹¶ä¸”è¿™ä¸ªè¿‡ç¨‹éœ€è¦å¯å¾®ã€‚è€Œåæ¸²æŸ“å¯ä»¥ç²—æµ…åœ°ç†è§£ä¸ºé€šè¿‡åŒä¸€ä¸ªç‰©ä½“çš„å¤šå¼ ä¸åŒè§’åº¦çš„rgbå›¾ç‰‡åæ¨å‡ºç‰©ä½“çš„å‡ ä½•æˆ–è€…å¤–è§‚å‚æ•°ã€‚æ¸²æŸ“æ˜¯ä¸€ä¸ªç¡®å®šçš„è¿‡ç¨‹ï¼Œè€Œåæ¸²æŸ“ç›®å‰çš„å¾ˆå¤šæ–¹æ³•éƒ½æ˜¯é€šè¿‡ç¥ç»ç½‘ç»œæ¥çŒœã€‚\n",
    "\n",
    "<img alt=\"æ¸²æŸ“è¿‡ç¨‹\" height=\"360\" src=\"images/3-2_2-rendering.png\" width=\"500\"/>\n",
    "\n",
    "### 1.1 å½¢çŠ¶è¡¨å¾\n",
    "ç›®å‰ä¸»æµçš„å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚å…¶ä¸­ï¼Œå‰ä¸‰ç§æ–¹å¼ç§°ä¸ºæ˜¾å¼çš„è¡¨å¾æ–¹å¼ï¼Œå®ƒä»¬ä¸€èˆ¬ä¾¿äºç¼–è¾‘ä½†æ¶ˆè€—èµ„æºæˆ–è€…é‡å»ºå›°éš¾ï¼›åä¸¤ç§æ–¹å¼ç§°ä¸ºéšå¼çš„è¡¨å¾æ–¹å¼ï¼Œå®ƒä»¬ä¸€èˆ¬é‡å»ºæ–¹ä¾¿ä½†ä¸æ˜“ç¼–è¾‘ï¼Œåä¸¤ç§æ–¹å¼éƒ½æ˜¯é€šè¿‡è¿ç”¨ç¥ç»ç½‘ç»œæ¥é¢„æµ‹çš„ï¼Œä¸€ä¸ªé¢„æµ‹[ç¬¦å·è·ç¦»å‡½æ•°](https://en.wikipedia.org/wiki/Signed_distance_function)çš„å€¼ï¼Œä¸€ä¸ªé¢„æµ‹å¯†åº¦å¯è§æ€§çš„å€¼ã€‚\n",
    "\n",
    "<img alt=\"æ¸²æŸ“è¿‡ç¨‹\" height=\"650\" src=\"images/3-1_1-shape-representation.png\" width=\"1200\"/>\n",
    "\n",
    "### 1.2 å¤–è§‚è¡¨å¾\n",
    "å¤–è§‚æ˜¯ä¸ªå¾ˆå¤§çš„æ¦‚å¿µï¼Œä¸€èˆ¬åˆåˆ†ä¸ºå¤–è§‚åˆç»†åˆ†ä¸ºå…‰ç…§ã€æè´¨ç­‰ç­‰ã€‚åœ¨æˆ‘ä»¬å¾—åˆ°ç‰©ä½“å’Œåœºæ™¯çš„å‡ ä½•å’Œå½¢çŠ¶ä¿¡æ¯ä¹‹åï¼Œç®€å•æ¥è¯´ï¼Œä¹‹åçš„æµç¨‹å¯ä»¥ç®€åŒ–æˆæˆ‘ä»¬æ˜¯æŠŠç‰©ä½“æè´¨çš„ä¿¡æ¯å¯¹åº”è´´åœ¨å‡ ä½•ä½“ä¸Šé¢ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚è€Œnerfçš„æ–¹å¼åˆ™æ˜¯å°†è¿™ä¸ªè¿‡ç¨‹ç»Ÿä¸€èµ·æ¥å¾—åˆ°RGBçš„é¢œè‰²ï¼Œåœ¨æ¥ä¸‹æ¥æˆ‘ä»¬å°†è¯¦ç»†ä»‹ç»ã€‚\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2 ç¥ç»è¾å°„åœºNeRF\n",
    "NeRF (Neural Radiance Fields) [wiki](https://en.wikipedia.org/wiki/Neural_radiance_field)åšçš„äº‹æƒ…å®è´¨å°±æ˜¯æŠŠå½¢çŠ¶å’Œå¤–è§‚ç›´æ¥é€šè¿‡rgbå€¼è¡¨ç¤ºå‡ºæ¥ï¼Œä¸éœ€è¦èµ°ä¼ ç»Ÿå›¾å½¢å­¦çš„é‚£ä¸€å¥—pipelineï¼Œè¿™æ—¢æ˜¯å®ƒçš„ä¼˜ç‚¹ï¼ˆå¯ä»¥å¾ˆæ–¹ä¾¿çš„è¡¨å¾åœºæ™¯ï¼‰ä¹Ÿæ˜¯ä»–çš„ç¼ºç‚¹ï¼ˆæ— æ³•èå…¥ç®¡çº¿ï¼Œä½¿ç”¨ä¸æ–¹ä¾¿ï¼Œç¼–è¾‘å›°éš¾ï¼‰ã€‚\n",
    "é¦–å…ˆï¼Œæˆ‘ä»¬å…ˆç›´è§‚çš„æ„Ÿå—ä¸‹nerfåšçš„äº‹æƒ…ã€‚\n",
    "\n",
    "<img alt=\"ä»‹ç»\" height=\"800\" src=\"./images/3-2_5-nerf-demo.gif\" width=\"1400\"/>\n",
    "\n",
    "ç„¶åæ¥çœ‹nerfçš„frameworkã€‚\n",
    "\n",
    "![nerf network](./images/3-2_3-nerf1.png)\n",
    "å…¶å®å®ƒåšçš„å°±æ˜¯è¾“å…¥ä¸€äº›è§†è§’çš„å›¾ç‰‡ï¼Œç„¶åä¸¢åˆ°ç¥ç»ç½‘ç»œä¸­å»é¢„æµ‹æ–°è§†è§’çš„å›¾ç‰‡ã€‚\n",
    "\n",
    "å…·ä½“è€Œè¨€å°±æ˜¯è¾“å…¥ä¸€äº›ç©ºé—´ä¸­çš„åæ ‡ç‚¹çš„ä½ç½®å’Œæ–¹å‘è§’ä¿¡æ¯ï¼Œä¹‹åé€šè¿‡ç¥ç»ç½‘ç»œæ¥é¢„æµ‹è¿™äº›ç‚¹çš„ä¸é€æ˜åº¦çš„å€¼ä»¥åŠè¯¥ç‚¹çš„é¢œè‰²ï¼Œæœ€åé€šè¿‡renderingçš„æ–¹æ³•æ¥å¾—åˆ°æ¯ä¸ªåƒç´ çš„é¢œè‰²å€¼ï¼Œå¾ˆå¤šä¸ªåƒç´ æœ€ç»ˆç»„æˆæ•´å¼ å›¾ç‰‡çš„rgbå€¼ã€‚\n",
    "![nerf network](./images/3-2_4-nerf2.png)\n",
    "\n",
    "çŸ¥é“è¿™äº›ä¹‹ååŸºæœ¬å°±å¯ä»¥ç†è§£åé¢ç« èŠ‚çš„å†…å®¹äº†ï¼Œå¦‚æœæƒ³è¿›ä¸€æ­¥äº†è§£åŸç†çš„ä¸œè¥¿ï¼Œå¯ä»¥å‚è€ƒä»¥ä¸‹èµ„æ–™ï¼š\n",
    "\n",
    "> [NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis](https://arxiv.org/pdf/2003.08934.pdf)\n",
    ">\n",
    "> [NeRF](https://www.matthewtancik.com/nerf)\n",
    ">\n",
    "> [éƒ½2022å¹´äº†ï¼Œæˆ‘ä¸å…è®¸ä½ è¿˜ä¸æ‡‚NeRF](https://zhuanlan.zhihu.com/p/569843149)\n",
    ">\n",
    "> [NeRFä»£ç è§£è¯»-ç›¸æœºå‚æ•°ä¸åæ ‡ç³»å˜æ¢](https://zhuanlan.zhihu.com/p/593204605)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3 ä»£ç æ¼”ç¤º\n",
    "> ä»£ç å‚è€ƒï¼š[nerfstudio-colab](https://colab.research.google.com/github/nerfstudio-project/nerfstudio/blob/main/colab/demo.ipynb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1 ä¾èµ–åº“å®‰è£…"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%cd /content/\n",
    "!pip install --upgrade pip\n",
    "!pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 --extra-index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# Installing TinyCuda\n",
    "%cd /content/\n",
    "!gdown \"https://drive.google.com/u/1/uc?id=1-7x7qQfB7bIw2zV4Lr6-yhvMpjXC84Q5&confirm=t\"\n",
    "!pip install tinycudann-1.7-cp310-cp310-linux_x86_64.whl\n",
    "\n",
    "# Installing COLMAP\n",
    "%cd /content/\n",
    "!gdown \"https://drive.google.com/u/0/uc?id=15WngFRNar_b8CaPR5R-hvQ3eAnlyk_SL&confirm=t\"\n",
    "!sudo apt-get install \\\n",
    "    build-essential \\\n",
    "    libboost-program-options-dev \\\n",
    "    libboost-filesystem-dev \\\n",
    "    libboost-graph-dev \\\n",
    "    libboost-system-dev \\\n",
    "    libboost-test-dev \\\n",
    "    libeigen3-dev \\\n",
    "    libflann-dev \\\n",
    "    libfreeimage-dev \\\n",
    "    libmetis-dev \\\n",
    "    libgoogle-glog-dev \\\n",
    "    libgflags-dev \\\n",
    "    libsqlite3-dev \\\n",
    "    libglew-dev \\\n",
    "    qtbase5-dev \\\n",
    "    libqt5opengl5-dev \\\n",
    "    libcgal-dev \\\n",
    "    libceres-dev\n",
    "!unzip local.zip -d /usr/\n",
    "!chmod +x /usr/local/bin/colmap\n",
    "\n",
    "# Install nerfstudio\n",
    "%cd /content/\n",
    "!pip install git+https://github.com/nerfstudio-project/nerfstudio.git"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2 ä¸‹è½½å¹¶å‡†å¤‡æ•°æ®é›†"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#@markdown <h3>Pick the preset scene or upload your own images/video</h3>\n",
    "import os\n",
    "import glob\n",
    "from google.colab import files\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "scene = '\\uD83D\\uDE9C dozer' #@param ['ğŸ–¼ poster', 'ğŸšœ dozer', 'ğŸŒ„ desolation', 'ğŸ“¤ upload your images' , 'ğŸ¥ upload your own video', 'ğŸ”º upload Polycam data', 'ğŸ’½ upload your own Record3D data']\n",
    "scene = ' '.join(scene.split(' ')[1:])\n",
    "\n",
    "if scene == \"upload Polycam data\":\n",
    "    %cd /content/\n",
    "    !mkdir -p /content/data/nerfstudio/custom_data\n",
    "    %cd /content/data/nerfstudio/custom_data/\n",
    "    uploaded = files.upload()\n",
    "    dir = os.getcwd()\n",
    "    if len(uploaded.keys()) > 1:\n",
    "        print(\"ERROR, upload a single .zip file when processing Polycam data\")\n",
    "    dataset_dir = [os.path.join(dir, f) for f in uploaded.keys()][0]\n",
    "    !ns-process-data polycam --data $dataset_dir --output-dir /content/data/nerfstudio/custom_data/\n",
    "    scene = \"custom_data\"\n",
    "elif scene == 'upload your own Record3D data':\n",
    "    display(HTML('<h3>Zip your Record3D folder, and upload.</h3>'))\n",
    "    display(HTML('<h3>More information on Record3D can be found <a href=\"https://docs.nerf.studio/en/latest/quickstart/custom_dataset.html#record3d-capture\" target=\"_blank\">here</a>.</h3>'))\n",
    "    %cd /content/\n",
    "    !mkdir -p /content/data/nerfstudio/custom_data\n",
    "    %cd /content/data/nerfstudio/custom_data/\n",
    "    uploaded = files.upload()\n",
    "    dir = os.getcwd()\n",
    "    preupload_datasets = [os.path.join(dir, f) for f in uploaded.keys()]\n",
    "    record_3d_zipfile = preupload_datasets[0]\n",
    "    !unzip $record_3d_zipfile -d /content/data/nerfstudio/custom_data\n",
    "    custom_data_directory = glob.glob('/content/data/nerfstudio/custom_data/*')[0]\n",
    "    !ns-process-data record3d --data $custom_data_directory --output-dir /content/data/nerfstudio/custom_data/\n",
    "    scene = \"custom_data\"\n",
    "elif scene in ['upload your images', 'upload your own video']:\n",
    "    display(HTML('<h3>Select your custom data</h3>'))\n",
    "    display(HTML('<p/>You can select multiple images by pressing ctrl, cmd or shift and click.<p>'))\n",
    "    display(HTML('<p/>Note: This may take time, especially on higher resolution inputs, so we recommend to download dataset after creation.<p>'))\n",
    "    !mkdir -p /content/data/nerfstudio/custom_data\n",
    "    if scene == 'upload your images':\n",
    "        !mkdir -p /content/data/nerfstudio/custom_data/raw_images\n",
    "        %cd /content/data/nerfstudio/custom_data/raw_images\n",
    "        uploaded = files.upload()\n",
    "        dir = os.getcwd()\n",
    "    else:\n",
    "        %cd /content/data/nerfstudio/custom_data/\n",
    "        uploaded = files.upload()\n",
    "        dir = os.getcwd()\n",
    "    preupload_datasets = [os.path.join(dir, f) for f in uploaded.keys()]\n",
    "    del uploaded\n",
    "    %cd /content/\n",
    "\n",
    "    if scene == 'upload your images':\n",
    "        !ns-process-data images --data /content/data/nerfstudio/custom_data/raw_images --output-dir /content/data/nerfstudio/custom_data/\n",
    "    else:\n",
    "        video_path = preupload_datasets[0]\n",
    "        !ns-process-data video --data $video_path --output-dir /content/data/nerfstudio/custom_data/\n",
    "\n",
    "    scene = \"custom_data\"\n",
    "else:\n",
    "    %cd /content/\n",
    "    !ns-download-data nerfstudio --capture-name=$scene\n",
    "\n",
    "print(\"Data Processing Succeeded!\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.3 å»ºç«‹å¹¶å¯åŠ¨viewer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%cd /content\n",
    "\n",
    "# Install localtunnel\n",
    "# We are using localtunnel https://github.com/localtunnel/localtunnel but ngrok could also be used\n",
    "!npm install -g localtunnel\n",
    "\n",
    "# Tunnel port 7007, the default for\n",
    "!rm url.txt 2> /dev/null\n",
    "get_ipython().system_raw('lt --port 7007 >> url.txt 2>&1 &')\n",
    "\n",
    "import time\n",
    "time.sleep(3) # the previous command needs time to write to url.txt\n",
    "\n",
    "\n",
    "with open('url.txt') as f:\n",
    "  lines = f.readlines()\n",
    "websocket_url = lines[0].split(\": \")[1].strip().replace(\"https\", \"wss\")\n",
    "# from nerfstudio.utils.io import load_from_json\n",
    "# from pathlib import Path\n",
    "# json_filename = \"nerfstudio/nerfstudio/viewer/app/package.json\"\n",
    "# version = load_from_json(Path(json_filename))[\"version\"]\n",
    "url = f\"https://viewer.nerf.studio/?websocket_url={websocket_url}\"\n",
    "print(url)\n",
    "print(\"You may need to click Refresh Page after you start training!\")\n",
    "from IPython import display\n",
    "display.IFrame(src=url, height=800, width=\"100%\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.4 å¼€å§‹è®­ç»ƒ"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%cd /content\n",
    "if os.path.exists(f\"data/nerfstudio/{scene}/transforms.json\"):\n",
    "    !ns-train nerfacto --viewer.websocket-port 7007 nerfstudio-data --data data/nerfstudio/$scene --downscale-factor 4\n",
    "else:\n",
    "    from IPython.core.display import display, HTML\n",
    "    display(HTML('<h3 style=\"color:red\">Error: Data processing did not complete</h3>'))\n",
    "    display(HTML('<h3>Please re-run `Downloading and Processing Data`, or view the FAQ for more info.</h3>'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
