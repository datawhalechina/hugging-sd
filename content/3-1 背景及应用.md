# 3-1 背景及应用

   * [0 章节目标](#0-章节目标)
   * [1 三维生成](#1-三维生成)
      * [1.1 三维重建](#11-三维重建)
      * [1.2 建模方式](#12-建模方式)
      * [1.3 进展和应用](#13-进展和应用)

    
## 0 章节目标

- 了解三维场景重建等相关技术
- 了解stable-diffusion在三维生成中的应用

## 1 三维生成

### 1.1 三维重建
在计算机视觉和计算机图形学中，3D重建是采用某种方式去尽可能真实地表示物体的形状和外观(包括物体材质、环境光照等)，该技术广泛应用于自动驾驶、机器人导航、虚拟现实、数字人等。[[wiki](https://en.wikipedia.org/wiki/3D_reconstruction)]


### 1.2 建模方式
为了给大家直观地介绍，这里我们只看三维重建过程中的形状重建（Shape Representation），也是三维重建中最为关键的一部分之一。

目前，主要采用这几类方法。

![形状建模的主要方式](/content/images/3-1_1-shape-representation.png)


其中，前三种方式称为显式的表征方式，它们一般便于编辑但消耗资源或者重建困难；后两种方式称为隐式的表征方式，它们一般重建方便但不易编辑，是随着深度学习方法兴起而兴起的方法，近两年来是炙手可热的研究方向。

后者将在下一章节中着重介绍[3-2 NeRF神经辐射场](https://en.wikipedia.org/wiki/Neural_radiance_field)

### 1.3 进展和应用
三维生成目前主流的方法分为两个派系。

一种是以3d点云+diffusion的点云扩散派，例如[point-e](https://github.com/openai/point-e)、[shape-e](https://github.com/openai/shap-e)等工作。

![3d点云+diffusion](/content/images/3-1_2-3d-diffusion.png)


<table>
    <tbody>
        <tr>
            <td align="center">
                <img src="https://github.com/openai/shap-e/blob/main/samples/a_chair_that_looks_like_an_avocado/2.gif" alt="A chair that looks like an avocado">
            </td>
            <td align="center">
                <img src="https://github.com/openai/shap-e/blob/main/samples/an_airplane_that_looks_like_a_banana/3.gif" alt="An airplane that looks like a banana">
            </td align="center">
            <td align="center">
                <img src="https://github.com/openai/shap-e/blob/main/samples/a_spaceship/0.gif" alt="A spaceship">
            </td>
        </tr>
        <tr>
            <td align="center">A chair that looks<br>like an avocado</td>
            <td align="center">An airplane that looks<br>like a banana</td>
            <td align="center">A spaceship</td>
        </tr>
        <tr>
            <td align="center">
                <img src="https://github.com/openai/shap-e/blob/main/samples/a_birthday_cupcake/3.gif" alt="A birthday cupcake">
            </td>
            <td align="center">
                <img src="https://github.com/openai/shap-e/blob/main/samples/a_chair_that_looks_like_a_tree/2.gif" alt="A chair that looks like a tree">
            </td>
            <td align="center">
                <img src="https://github.com/openai/shap-e/blob/main/samples/a_green_boot/3.gif" alt="A green boot">
            </td>
        </tr>
        <tr>
            <td align="center">A birthday cupcake</td>
            <td align="center">A chair that looks<br>like a tree</td>
            <td align="center">A green boot</td>
        </tr>
        <tr>
            <td align="center">
                <img src="https://github.com/openai/shap-e/blob/main/samples/a_penguin/1.gif" alt="A penguin">
            </td>
            <td align="center">
                <img src="https://github.com/openai/shap-e/blob/main/samples/ube_ice_cream_cone/3.gif" alt="Ube ice cream cone">
            </td>
            <td align="center">
                <img src="https://github.com/openai/shap-e/blob/main/samples/a_bowl_of_vegetables/2.gif" alt="A bowl of vegetables">
            </td>
        </tr>
        <tr>
            <td align="center">A penguin</td>
            <td align="center">Ube ice cream cone</td>
            <td align="center">A bowl of vegetables</td>
        </tr>
    </tbody>
<table>


另一种是更有应用前景的2d生成大模型+nerf的升维派，顾名思义就是利用2d图片的先验信息来重建3d的场景表征。例如[dreamfusion](https://dreamfusion3d.github.io/)、[zero123](https://zero123.cs.columbia.edu/)、[prolificdreamer](https://github.com/thu-ml/prolificdreamer)等。

<video src="https://user-images.githubusercontent.com/25863658/232403162-51b69000-a242-4b8c-9cd9-4242b09863fa.mp4" controls>
  你的浏览器不支持 <code>video</code> 标签。
</video>

其中dreamfusion将在 [3-3 Dreamfusion原理]()中详细介绍，zero123将在[3-4 Zero123原理]()详细介绍。





