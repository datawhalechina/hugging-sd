# 第2章 对抗模型

&emsp;&emsp;从自然法则的角度来看，优胜劣汰是生命进化的核心机制，它推动了物种的适应与生存。在这个过程中，只有最能适应环境变化、最具竞争力的个体能够存活并繁衍后代，而那些不适应的个体则会逐渐被淘汰。对抗生成网络（GAN）在某种程度上模拟了这一自然法则。GAN的核心机制是通过生成器与判别器之间的对抗博弈，生成器不断尝试生成更加逼真的数据，而判别器则致力于区分真实数据与生成数据。在这个过程中，生成器和判别器如同自然选择中的两个“物种”，彼此不断竞争、进化，优胜者不断推动系统性能的提升。从自然法则的优胜劣汰视角来看，GAN不仅仅是一种数学模型，更是一种模拟生物进化的动态机制，它通过不断的对抗与进化，实现了生成模型的优化与提升。


## 2.1 对抗生成网络(GAN)

> It is not the strongest of the species that survive, but the one most responsive to change（物竞天择，适者生存） -- Charles Darwin

&emsp;&emsp;本小节介绍生成对抗网络（Generative Adversarial Networks，简称GAN），它也是一种生成模型，由伊恩·古德费洛等人在2014年提出。GANs通过生成器（Generator）和判别器（Discriminator）之间的对抗性过程来学习和生成数据。在GAN的训练过程中，生成器不断优化其生成策略，力求“骗过”判别器，而判别器则必须通过识别生成数据的伪造痕迹来保持其竞争优势。随着训练的进行，生成器和判别器都不断适应对方的策略，彼此之间的博弈使得生成器能够产生越来越真实的数据。这一过程与自然界中的优胜劣汰机制相似，强调通过竞争和不断适应环境的变化来提升个体的能力。最终，只有经过这一过程的模型，才能在复杂的任务中取得成功，产生高质量的结果。生成器的目标是捕捉数据分布，并生成与训练数据相似的新数据样本，生成器的输出旨在尽可能欺骗判别器，使其认为生成的数据是真实的。判别器的目标是区分真实数据和生成器生成的假数据，判别器在不断提高其区分能力，使其能够更准确地区分真实数据和生成数据。

&emsp;&emsp;何谓生成器？假设有一个猫咪的数据集，服从 $P_{data}(x)$ 的未知分布，生成器$G$的目标就是利用极大似然估计的方法来确定$\theta$来学习一个分布 $P_{G}(x;\theta )$ ，使得学习的 $P_{G}(x;\theta )$ 分布与目标数据集分布 $P_{data}(x)$ 越接近越好。接下来，如果想要生成猫咪的图片，只需要在学得的 $P_{G}(x;\theta )$ 采样即可。学习的分布离真实猫咪分布约接近，那么生成图片的猫咪也会越真实。

如何设计目标函数使得$P_{G}(x;\theta )$ 分布趋近于目标数据集分布 $P_{data}(x)$ 呢？前一章节提到的VAE的方法是采用KL散度来衡量两个分布的相似程度，而GAN则是通过巧妙地设计网络结构，将衡量两个分布相似程度地任务丢给神经网络判别起来判断，其框架图如图1.3所示。

<div align=center>
<img width="600" src="./images/chapter2/GAN_framework.png"/>
</div>
<div align=center>图2.1 GAN框架结构图</div>

GAN的原理是首先初始化一个正太分布的噪声，然后通过生成器网络生成猫的图片，然后将生成的猫的图片给判别器，让它判别该图片是真实图片还是生成的图片。判别器由真实猫咪的图片训练而来。在这个过程中不断迭代优化生成器使得生成的图片更像猫，同时使得判别器能更准确判别图片是否是生成的，优化函数描述为：

$$
\min_G\max_DV(D,G)=\mathbb{E}_{\boldsymbol{x}\sim p_\mathrm{data}(\boldsymbol{x})}[\log D(\boldsymbol{x})]\boldsymbol{+}\mathbb{E}_{\boldsymbol{z}\sim p_{\boldsymbol{z}}(\boldsymbol{z})}[\log(1\boldsymbol{-}D(G(\boldsymbol{z})))].
$$

这样的过程恰似自然界中捕食者和被捕食着之间此起彼伏的竞争，但又相互依赖，相互进化。



## 2.2 架构优化与条件生成

&emsp;&emsp;最初的GAN模型使用全连接的多层感知器（MLP）作为生成器和判别器。虽然这种架构适用于一些简单的数据集（如MNIST），但在处理图像等复杂数据时，效果不佳。原因是多层感知器在处理图像信息时遇到以下问题：

- MLP不考虑图像中的空间结构信息，尽管MLP能够通过其全连接的层学习到某些全局特征，但它无法有效捕捉到图像中像素间的相邻关系或局部模式，导致它提取图片特征的能力有限。
- MLP中的每一层的神经元都与上一层的每个神经元全连接，因此需要大量的参数来描述网络的权重。特别是在处理高维图像时，参数的数量呈指数级增长，计算和存储开销非常大。
- 由于MLP没有考虑图像的空间结构，它对于图像中的物体位置变化较为敏感。例如，图像中的物体如果发生平移或者旋转，MLP的输出可能会发生较大变化

彼时的卷积神经网络（CNN）风光无两，并且其局部信息的捕捉、高效的高维特征提取以及平移不变性的特性，能非常好地处理以上问题，于是**Radford**等人提出了DCGAN，通过将生成器和判别器的网络结构从MLP替换为CNN的结构，如图2.2所示。

<div align=center>
<img width="600" src="./images/chapter2/DCGAN_framework.png"/>
</div>
<div align=center>图2.2 DCGAN采用的生成器结构</div>

同时，GAN还面临着训练慢和不稳定等问题，DCGAN在模型结构和数据提取上做了一些小技巧：

- DCGAN的生成器和判别器中都采用了批量归一化层，这有助于加速训练过程，稳定训练并提升生成效果。
- DCGAN在生成器中使用ReLU激活函数（除了输出层使用Tanh），而判别器使用Leaky ReLU激活函数（除了输出层使用Sigmoid）。因为ReLU的非线性帮助生成器捕捉到这些复杂的模式，并且它能避免梯度消失和进行稀疏激活。

&emsp;&emsp;其实，上一章的VAE、VQVAE以及本章节中的GAN、DCGAN都是无监督学习，即它们不用标签监督即可学习数据中的关系特征。但是这样的模型却无法被我们直接使用，因为在大多数时候，无监督的生成往往随机不可控，但是人们对生成的内容有要求，比如生成猫或者狗，长毛或短毛等等。那么这就要求我们需要用条件控制模型生成，上一章的CVAE以及接下来要介绍的条件生成对抗模型（CGAN）都是监督学习范式。CGAN的整体思路同样也是概率模型变为条件概率模型，如图2.3所示。


<div align=center>
<img width="600" src="./images/chapter2/CGAN_framework.png"/>
</div>
<div align=center>图2.2 CGAN模型框架结构</div>



其中，红色的线条表示生成器的训练过程，黑色的线条表示判别器的训练过程，可以看出整体就是在GAN的基础上加上了条件控制训练，优化函数描述为：

$$
\min_G\max_DV(D,G)=\mathbb{E}_{\boldsymbol{x}\sim p_\mathrm{data}(\boldsymbol{x})}[\log D(\boldsymbol{x|y})]\boldsymbol{+}\mathbb{E}_{\boldsymbol{z}\sim p_{\boldsymbol{z}}(\boldsymbol{z})}[\log(1\boldsymbol{-}D(G(\boldsymbol{z|y})))].
$$


## 2.3 风格控制
